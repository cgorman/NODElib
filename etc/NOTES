Additions to optmizer.h for return codes:

OPT_NO_ENGINE
OPT_HOOK_RETURN
OPT_HALTF_RETURN
OPT_ERROR_TOL
OPT_DELTA_ERROR_TOL
OPT_DECAY_ERROR_TOL
OPT_DECAY_DELTA_ERROR_TOL
OPT_MAX_EPOCHS_REACHED
OPT_ZERO_GRAD
OPT_DIV_ZERO
OPT_GRAD_DIR_ORTHOGONAL
OPT_INTERPOLATE_FAILED
OPT_EXTRAPOLATE_FAILED
OPT_MIN_DELTA_STEP
OPT_MIN_DELTA_ERROR
OPT_MAX_LINE_STEPS
OPT_BRACKET_FAILED

###############################################################################

NODElib
 * Support Routines
    * Misc
    * Ulog
    * Xalloc
 * Low-Level Data Stuctures
    * Array 
    * Hash
    * Scan
 * Data Manipulation
    * Dataset & Dsmethod
       * Dsdblptr
       * Dsfile
       * Dsmatrix
       * Dsfile
       * Dssubset
    * Series
 * Numerical Code
    * Data
       * Dense
       * Kmeans
    * SVD
       * Pinv, Spinv
       * SVD
       * PCA
    * Errfunc
    * Optimize
       * Linesearch
          * Golden
          * Cubicinterp
          * Hybrid
       * Dirsearch    
          * Graddesc
          * Prcongrad
          * Frcongrad
          * Bfgsqnewt
          * Dfpsqnewt
    * NN
  
###############################################################################

# Lapack SVD test results  

sizes='5 10 15 20 25 30 40 50 60 70 80 90 100 150 200 250 300'

#rm -rf svdlapack.txt svdorig.txt

for n in $sizes; do
  echo -n Doing $n with original ... 
  t=`(time ./tpinv -orig -n $n > /dev/null) 2>&1 | \
     head -1 | awk '{print $1}' | sed 's/\([^a-z]*\)[a-z]*/\1/g'`
  echo $n $t >> svdorig.txt
  echo done

  echo -n Doing $n with LAPACK ... 
  t=`(time ./tpinv -n $n > /dev/null) 2>&1 | \
     head -1 | awk '{print $1}' | sed 's/\([^a-z]*\)[a-z]*/\1/g'`
  echo $n $t >> svdlapack.txt
  echo done

  echo ""
done


exit 0

cat << EOF > /dev/null

Some notes:

N	orig	lapack	orig/lapack
---	----	------  -----------
5	0.01	0.03	0.33333
10	0.02	0.05 	0.4    
15	0.05	0.06 	0.83333
20	0.09	0.10 	0.9    
25	0.18	0.16 	1.125  
30	0.23	0.22 	1.04545
40	0.63	0.40 	1.575  
50	1.41	0.65 	2.16923
60	2.61	1.03 	2.53398
70	5.34	1.53 	3.4902 
80	11.27	2.23 	5.05381
90	14.88	2.92 	5.09589
100	23.37	3.80 	6.15   
150	155.07	11.78	13.1638
200	619.42	30.69	20.1831
250     1486.99	60.50	24.5783
300	3376.61	108.20	31.2071
1724	???????	25245.7	???????

EOF

###############################################################################

Some notes on the change in memory managment:

1.12.0: old version with point to weights
1.13.0: some changes to line search interface to use local memory
1.13.1: fixes to some line searches
1.14.0: simplification of NN memory - optimization does copy
1.14.1: short-circuit calculation of gradients
1.15.0: optimization uses pointer to pointers

I need to run test so that gradient and function evaluations are
counted.

Problem: train 6-40-1 RBF with centers and variances locked on about
         2000 patterns.  Numbers below are average per epoch.


Version fcalls gcalls error      time     time / (2 * gcalls + fcalls)
----------------------------------------------------------------------
12.0    161.4  107.8  0.0278502  90.158   0.239079
13.0    161.4  107.8  0.0278502  88.885   0.235705
13.1    102    183.1  0.0280164  108.335  0.231422
14.0    102.6  182.9  0.0291143  85.55    0.18263
14.1    102.6  182.9  0.0291143  93.444   0.199484
15.0    102    133.1  0.0280164  62.695   0.170333


        154.2  129.7  0.0285902  106.327  0.257102
        154.2  129.7  0.0285902  104.404  0.252439
        105.2  186.3  0.0278632  122.997  0.257425
        105.2  186.3  0.0278632  132.753  0.277831
        105.2  186.3  0.0278632  115.874  0.242516
        105.2  136.3  0.0278632  86.733   0.229575




###############################################################################
